hydra:
  job:
    chdir: False

train:
  dataset_name: ["JasiekKaczmarczyk/giant-midi-sustain-masked", "JasiekKaczmarczyk/pianofor-ai-sustain-masked", "JasiekKaczmarczyk/maestro-v1-sustain-masked"] # huggingface dataset
  batch_size: 768
  num_workers: 8
  lr: 3e-5
  weight_decay: 0.01
  pitch_shift_probability: 0.5
  time_stretch_probability: 0.5
  num_epochs: 10
  device: "cuda"
  precision: "16-mixed" # not implemented yet
  overfit_single_batch: False
  masking_ratio_scheduler:
    0: 0.15
    6e7: 0.2
    12e7: 0.25
    18e7: 0.3
    24e7: 0.35
    30e7: 0.4
    36e7: 0.45
    42e7: 0.5
  loss_lambdas:
    pitch: 1.
    velocity: 1.
    dstart: 1.
    duration: 1.


model:
  encoder_dim: 384
  encoder_depth: 6
  encoder_num_heads: 8
  decoder_dim: 256
  decoder_depth: 4
  decoder_num_heads: 8
  mlp_ratio: 2.

paths:
  save_ckpt_dir: "checkpoints" # directory where checkpoints will be saved
  load_ckpt_path: "checkpoints/mae10m-2023-11-09-09-28-params-9.88M.ckpt" # if not None, specifies path to model state dict which will be loaded
  log_dir: "logs"
  hf_repo_id: null # repo id to upload model to huggingface if null model is not uploaded

logger:
  run_name: mae10m-${now:%Y-%m-%d-%H-%M}
  log_every_n_steps: 10
